{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d435bae-c85f-4368-8cd5-0eff0928458e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba3631e-5016-40f4-bd46-cc91e7509f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,math,sys,torch,re,numpy as np\n",
    "from types import SimpleNamespace as ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e41709-f1f3-40c1-aa20-bd19737f3d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, linewidth=140)\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db47935d-8477-4116-9538-369c759322bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a76aa950-6f87-452d-b048-82da11be0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_img,load_cuda,cuda_begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994f69fd-3989-46e2-ad84-71b7450f1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed0d99b2-bf34-4e9c-99e5-0ebf4e4b02d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc38ccaa-c802-46c2-962a-e1f83eba49d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.rand(50_000, 784)\n",
    "m1s = m1[:8]\n",
    "m2 = torch.rand(784,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28662938-ef33-410b-96d4-d7d503c696d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reminder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9421c9-6cd5-479e-b3f2-7a3a8d2a7b43",
   "metadata": {},
   "source": [
    "### 2d Python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ef592ed-b605-46f5-b72d-662ab46a55e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_kernel2d(f, blocks, threads, *args):\n",
    "    for i0 in range(blocks.y):\n",
    "        for i1 in range(blocks.x):\n",
    "            for j0 in range(threads.y):\n",
    "                for j1 in range(threads.x): f(ns(x=i1,y=i0), ns(x=j1,y=j0), threads, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62f8923f-8072-4f52-a644-6576f7dfe352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_bk(blockidx, threadidx, blockdim, m, n, out, h, w, k):\n",
    "    r = blockidx.y*blockdim.y + threadidx.y\n",
    "    c = blockidx.x*blockdim.x + threadidx.x\n",
    "    \n",
    "    if (r>=h or c>=w): return\n",
    "    o = 0.\n",
    "    for i in range(k): o += m[r*k+i] * n[i*w+c]\n",
    "    out[r*w+c] = o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a53c2202-1169-4ac6-a477-82b82f3c5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_2d(m, n):\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    assert k==k2, \"Size mismatch!\"\n",
    "    output = torch.zeros(h, w, dtype=m.dtype)\n",
    "    tpb = ns(x=16,y=16)\n",
    "    blocks = ns(x=math.ceil(w/tpb.x), y=math.ceil(h/tpb.y))\n",
    "    blk_kernel2d(matmul_bk, blocks, tpb,\n",
    "                 m.flatten(), n.flatten(), output.flatten(), h, w, k)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e54824bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(matmul_2d(m1s, m2), m1s@m2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8023ed5e-6adb-4c00-b234-a80bf774baad",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f85d6e4-bc36-4171-b64e-3447359913e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_src = cuda_begin + r'''\n",
    "__global__ void matmul_k(float* m, float* n, float* out, int h, int w, int k) {\n",
    "    int r = blockIdx.y*blockDim.y + threadIdx.y;\n",
    "    int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
    "\n",
    "    if (r>=h || c>=w) return;\n",
    "    float o = 0;\n",
    "    for (int i = 0; i<k; ++i) o += m[r*k+i] * n[i*w+c];\n",
    "    out[r*w+c] = o;\n",
    "}\n",
    "\n",
    "torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h = m.size(0);\n",
    "    int w = n.size(1);\n",
    "    int k = m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
    "    auto output = torch::zeros({h, w}, m.options());\n",
    "\n",
    "    dim3 tpb(16,16);\n",
    "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
    "    matmul_k<<<blocks, tpb>>>(\n",
    "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a82414f-bd5a-4fb1-9f7f-1f404b8d8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'matmul'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d93c0b9a-2f20-460c-8393-3fb241c1ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig(fname, src):\n",
    "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
    "    return res[0]+';' if res else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b943b71-641c-4ec1-b336-7d04b4930c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch::Tensor matmul(torch::Tensor m, torch::Tensor n);'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_src = get_sig(fname, cuda_src)\n",
    "cpp_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9533561e-6426-4c29-92a6-3f968521d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = load_cuda(cuda_src, cpp_src, [fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d4e99ab-d2a7-45ef-a38f-f38ca17e22d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1c,m2c = m1.contiguous().cuda(),m2.contiguous().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08507713-c7b5-40b4-a7c0-a9ead64f3017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.matmul(m1c,m2c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80fc299e-8c08-40f2-9c17-cc1965b0b430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(module.matmul(m1c,m2c), m1c@m2c).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b1cf32-baa7-449b-ac0b-9d787d7bc470",
   "metadata": {},
   "source": [
    "## Shared mem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a31cf-b54f-4b8a-982f-51ff1a68bb6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2d Python kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49c2701c-ca6d-486d-b83b-b2e4e28193ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(5)\n",
    "b,c = a[:3],a[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2a59a4f-d902-40cb-8510-5f6866411f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 0., 6., 0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[1] = 2\n",
    "c[0] = 6\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d915f331-9bbd-4256-bdca-e1a74f38208c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_kernel2d_shar(f, blocks, threads, sh_sz, *args, **kwargs):\n",
    "    for i0 in range(blocks.y):\n",
    "        for i1 in range(blocks.x):\n",
    "            shared = torch.zeros(sh_sz)\n",
    "            f(ns(x=i1,y=i0), threads, shared, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a44f65b-3ad1-4654-92b9-5b61ede1a6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_threads(f, blockdim, *args, **kwargs):\n",
    "    for i0 in range(blockdim.y):\n",
    "        for i1 in range(blockdim.x): f(i0, i1, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "096fbfc1-5f01-4203-94df-98a62ddc2ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_tiled_bk(blockidx, blockdim, shared, m, n, out, h, w, k, tw):\n",
    "    shar_sz = tw*tw\n",
    "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
    "\n",
    "    def get_rc(ty, tx): return blockidx.y*blockdim.y + ty, blockidx.x*blockdim.x + tx\n",
    "\n",
    "    def fill_shared_tk(ty, tx, ph):\n",
    "        r,c = get_rc(ty, tx)\n",
    "        ms[ty*tw+tx] = m[ tx + ph*tw + r*k] if r<h and (ph*tw+tx)<k else 0.\n",
    "        ns[ty*tw+tx] = n[(ty + ph*tw)*w +c] if c<w and (ph*tw+ty)<k else 0.\n",
    "\n",
    "    def dotprod_tk(ty, tx):\n",
    "        r,c = get_rc(ty, tx)\n",
    "        for i in range(tw):\n",
    "            if r*w+c<len(out): out[r*w+c] += ms[ty*tw+i] * ns[tw*i+tx]\n",
    "\n",
    "    for ph in range(int(math.ceil(k/tw))):\n",
    "        run_threads(fill_shared_tk, blockdim, ph)\n",
    "        run_threads(dotprod_tk, blockdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0ae141e-be1a-42cd-85aa-64be0add9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_2d(m, n, tw=16):\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    assert k==k2, \"Size mismatch!\"\n",
    "    output = torch.zeros(h, w, dtype=m.dtype)\n",
    "    tpb = ns(x=tw,y=tw)\n",
    "    blocks = ns(x=math.ceil(w/tpb.x), y=math.ceil(h/tpb.y))\n",
    "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
    "                      m.flatten(), n.flatten(), output.flatten(),\n",
    "                      h, w, k, tw=tw)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb489de0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1s.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e65cb4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(matmul_2d(m1s, m2, tw=16), m1s@m2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b204c2-e349-4afb-9787-a9a045b78977",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2d Python kernel threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa6aec96-1e67-4d6d-81af-1f6c3cb6de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from threading import Barrier, Thread\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28306d45-3176-4cef-95f1-5894cf494c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x, sb):\n",
    "    print(x)\n",
    "    sb.wait()\n",
    "    print(-x)\n",
    "    sb.wait()\n",
    "    print(x*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff4e712e-5999-4e4b-a057-db65996b657d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "-2\n",
      "-1\n",
      "0\n",
      "10\n",
      "0\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "num = 3\n",
    "sb = Barrier(num)\n",
    "with ThreadPoolExecutor(num) as ex: list(ex.map(lambda i: g(i,sb), range(num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bac722db-cea2-494f-9ad0-a46c010e61e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blk_kernel2d_shar(f, blocks, tpb, sh_sz, *args, **kwargs):\n",
    "    for i0 in range(blocks.y):\n",
    "        for i1 in range(blocks.x):\n",
    "            shar = torch.zeros(sh_sz)\n",
    "            syncb = Barrier(tpb.y*tpb.x)\n",
    "            threads = [Thread(target=f, args=(ns(x=i1,y=i0), ns(x=p,y=o), tpb, shar, syncb, *args), kwargs=kwargs)\n",
    "                       for o in range(tpb.y) for p in range(tpb.x)]\n",
    "            for t in threads: t.start()\n",
    "            for t in threads: t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58f86730-7484-404d-b542-861a5516aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_tiled_bk(blockidx, threadidx, blockdim, shared, syncb, m, n, out, h, w, k, tw):\n",
    "    tx,ty = threadidx.x,threadidx.y\n",
    "    r = blockidx.y*blockdim.y + ty\n",
    "    c = blockidx.x*blockdim.x + tx\n",
    "\n",
    "    shar_sz = tw*tw\n",
    "    ms,ns = shared[:shar_sz],shared[shar_sz:]\n",
    "\n",
    "    p = 0.\n",
    "    for ph in range(int(math.ceil(k/tw))):\n",
    "        ms[ty*tw+tx] = m[ tx + ph*tw + r*k] if r<h and (ph*tw+tx)<k else 0.\n",
    "        ns[ty*tw+tx] = n[(ty + ph*tw)*w +c] if c<w and (ph*tw+ty)<k else 0.\n",
    "        syncb.wait()\n",
    "        for i in range(tw): p += ms[ty*tw+i] * ns[tw*i+tx]\n",
    "        syncb.wait()\n",
    "\n",
    "    if (r<h and c<w): out[r*w + c] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f758eb6b-fc56-43e0-943f-3afd8ce86dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul_2d(m, n, tw=16):\n",
    "    h,k  = m.shape\n",
    "    k2,w = n.shape\n",
    "    assert k==k2, \"Size mismatch!\"\n",
    "    output = torch.zeros(h, w, dtype=m.dtype)\n",
    "    tpb = ns(x=tw,y=tw)\n",
    "    blocks = ns(x=math.ceil(w/tpb.x), y=math.ceil(h/tpb.y))\n",
    "    blk_kernel2d_shar(matmul_tiled_bk, blocks, tpb, tw*tw*2,\n",
    "                      m.flatten(), n.flatten(), output.flatten(),\n",
    "                      h, w, k, tw=tw)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "270af122-7282-4934-833d-6fe195efc7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.8 s, sys: 10.4 s, total: 19.2 s\n",
      "Wall time: 10.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.isclose(matmul_2d(m1s, m2, tw=8), m1s@m2).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d5c80-8969-4a87-85b6-2776b3d965f0",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e991187-cd90-41e5-b197-d68e51fcd26b",
   "metadata": {},
   "source": [
    "#### Manual Tiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c8e2807-66c3-4789-bd59-63dadee9d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <cuda_runtime.h>\n",
    "#include <math.h>\n",
    "cuda_src = cuda_begin + r'''\n",
    "#define TW 16\n",
    "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k) {\n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "    int bx = blockIdx.x;\n",
    "    int by = blockIdx.y;\n",
    "    int bw = blockDim.x;\n",
    "    int bh = blockDim.y;\n",
    "\n",
    "    int row = by * bh + ty;\n",
    "    int col = bx * bw + tx;\n",
    "\n",
    "    __shared__ float ms[TW*TW];\n",
    "    __shared__ float ns[TW*TW];\n",
    "\n",
    "    float p = 0.0;\n",
    "\n",
    "    for (int ph = 0; ph < ceil((float)k / TW); ++ph) {\n",
    "        int mIndex = row * k + ph * TW + tx;\n",
    "        int nIndex = (ph * TW + ty) * w + col;\n",
    "        \n",
    "        if (row < h && (ph * TW + tx) < k)\n",
    "            ms[ty * TW + tx] = m[mIndex];\n",
    "        else\n",
    "            ms[ty * TW + tx] = 0.0;\n",
    "\n",
    "        if (col < w && (ph * TW + ty) < k)\n",
    "            ns[ty * TW + tx] = n[nIndex];\n",
    "        else\n",
    "            ns[ty * TW + tx] = 0.0;\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int i = 0; i < TW; ++i)\n",
    "            p += ms[ty * TW + i] * ns[i * TW + tx];\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (row < h && col < w)\n",
    "        out[row * w + col] = p;\n",
    "}\n",
    "\n",
    "torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h = m.size(0);\n",
    "    int w = n.size(1);\n",
    "    int k = m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
    "    auto output = torch::zeros({h, w}, m.options());\n",
    "\n",
    "    dim3 tpb(16,16);\n",
    "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
    "\n",
    "    printf(\"blocks.x: %u blocks.y: %u\", blocks.x, blocks.y);\n",
    "    printf(\"tpb.x: %u tpb.y: %u\", tpb.x, tpb.y);\n",
    "\n",
    "\n",
    "    matmul_k<<<blocks,tpb>>>(\n",
    "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "511727bb-33a9-4e29-b65d-fd79257bbf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'matmul'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6ee310-95d3-4b4a-a1ca-130f899a96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig(fname, src):\n",
    "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
    "    return res[0]+';' if res else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c7cc97b-76e9-4322-8ec4-a02d7c77f6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch::Tensor matmul(torch::Tensor m, torch::Tensor n);'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_src = get_sig(fname, cuda_src)\n",
    "cpp_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110c2ee9-394d-44e4-8079-10a0ded20489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ubuntu/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "The input conditions for extension module inline_ext have changed. Bumping to version 1 and re-building as inline_ext_v1...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py311_cu121/inline_ext/build.ninja...\n",
      "Building extension module inline_ext_v1...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=inline_ext_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/TH -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/miniconda3/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/ubuntu/.cache/torch_extensions/py311_cu121/inline_ext/main.cpp -o main.o \n",
      "[2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=inline_ext_v1 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/TH -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/miniconda3/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -std=c++17 -c /home/ubuntu/.cache/torch_extensions/py311_cu121/inline_ext/cuda.cu -o cuda.cuda.o \n",
      "[3/3] c++ main.o cuda.cuda.o -shared -L/home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o inline_ext_v1.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module inline_ext_v1...\n"
     ]
    }
   ],
   "source": [
    "module = load_cuda(cuda_src, cpp_src, [fname], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61647be2-d0a3-4fba-ac7b-5dd186e2d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1c,m2c = m1.contiguous().cuda(),m2.contiguous().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c64bea8-778a-47ea-9f2a-e5a26ba6f36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.x: 1 blocks.y: 3125tpb.x: 16 tpb.y: 16"
     ]
    }
   ],
   "source": [
    "module.matmul(m1c,m2c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2ff0e83-b82c-4c33-bfef-3abeab547c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.x: 1 blocks.y: 3125tpb.x: 16 tpb.y: 16"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(module.matmul(m1c,m2c), m1c@m2c).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee683ac-16c5-47b9-9753-8053fec77c43",
   "metadata": {},
   "source": [
    "#### Dynamic Tiling\n",
    "\n",
    "Here we `extern __shared__ float ms_ns[]` to dynamically allocate the shared memory, which might vary based on the device properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55e1d880-7011-4e4e-9e87-7688dbad1da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <cuda_runtime.h>\n",
    "#include <math.h>\n",
    "cuda_src = cuda_begin + r'''\n",
    "__global__ void matmul_k(float *m, float *n, float *out, int h, int w, int k, int TW, unsigned size) {\n",
    "    int tx = threadIdx.x;\n",
    "    int ty = threadIdx.y;\n",
    "    int bx = blockIdx.x;\n",
    "    int by = blockIdx.y;\n",
    "    int bw = blockDim.x;\n",
    "    int bh = blockDim.y;\n",
    "\n",
    "    int row = by * bh + ty;\n",
    "    int col = bx * bw + tx;\n",
    "\n",
    "    extern __shared__ float ms_ns[];\n",
    "    float *ms = ms_ns;\n",
    "    float *ns = &ms_ns[TW*TW]; // Use number of elements to offset\n",
    "\n",
    "    // printf(\"ms_size: %u, ns_size: %u\", size/2, size/2);\n",
    "\n",
    "    float p = 0.0;\n",
    "\n",
    "    for (int ph = 0; ph < ceil((float)k / TW); ++ph) {\n",
    "        int mIndex = row * k + ph * TW + tx;\n",
    "        int nIndex = (ph * TW + ty) * w + col;\n",
    "        \n",
    "        if (row < h && (ph * TW + tx) < k)\n",
    "            ms[ty * TW + tx] = m[mIndex];\n",
    "        else\n",
    "            ms[ty * TW + tx] = 0.0;\n",
    "\n",
    "        if (col < w && (ph * TW + ty) < k)\n",
    "            ns[ty * TW + tx] = n[nIndex];\n",
    "        else\n",
    "            ns[ty * TW + tx] = 0.0;\n",
    "\n",
    "        __syncthreads();\n",
    "\n",
    "        for (int i = 0; i < TW; ++i)\n",
    "            p += ms[ty * TW + i] * ns[i * TW + tx];\n",
    "\n",
    "        __syncthreads();\n",
    "    }\n",
    "\n",
    "    if (row < h && col < w)\n",
    "        out[row * w + col] = p;\n",
    "}\n",
    "\n",
    "size_t calculateSharedMemorySize() {\n",
    "    // Query the first CUDA device\n",
    "    cudaDeviceProp devProp;\n",
    "    cudaError_t cudaStatus = cudaGetDeviceProperties(&devProp, 0);\n",
    "    if (cudaStatus != cudaSuccess) {\n",
    "        std::cerr << \"cudaGetDeviceProperties failed: \" << cudaGetErrorString(cudaStatus) << std::endl;\n",
    "        return 0; // Return 0 if unable to get device properties\n",
    "    }\n",
    "\n",
    "    // Use maxThreadsPerBlock from device properties\n",
    "    int maxThreads = devProp.maxThreadsPerBlock;\n",
    "\n",
    "    // Calculate the required size for shared memory based on maxThreads\n",
    "    size_t requiredSize = static_cast<size_t>(maxThreads) * 2 * 4; // Assuming 4 bytes per element (float)\n",
    "\n",
    "    // Take the minimum of devProp.sharedMemPerBlock and requiredSize\n",
    "    size_t size = min(devProp.sharedMemPerBlock, requiredSize);\n",
    "\n",
    "    // Output the calculated size\n",
    "    std::cout << \"Calculated shared memory size: \" << size << \" bytes\" << std::endl;\n",
    "\n",
    "    return size;\n",
    "}\n",
    "\n",
    "torch::Tensor matmul(torch::Tensor m, torch::Tensor n) {\n",
    "    CHECK_INPUT(m); CHECK_INPUT(n);\n",
    "    int h = m.size(0);\n",
    "    int w = n.size(1);\n",
    "    int k = m.size(1);\n",
    "    TORCH_CHECK(k==n.size(0), \"Size mismatch!\");\n",
    "    auto output = torch::zeros({h, w}, m.options());\n",
    "\n",
    "    size_t size = calculateSharedMemorySize();\n",
    "    // size_t size = 2048; // test with fixed size\n",
    "    \n",
    "    printf(\"Maximum shared memory per block: %zu bytes\\n\", size);\n",
    "\n",
    "    int TW = std::sqrt(size / 2 / sizeof(float));\n",
    "    dim3 tpb(TW,TW);\n",
    "    dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
    "\n",
    "    printf(\"TW: %u \", TW);\n",
    "    printf(\"blocks.x: %u blocks.y: %u\\n\", blocks.x, blocks.y);\n",
    "    printf(\"tpb.x: %u tpb.y: %u\\n\", tpb.x, tpb.y);\n",
    "\n",
    "    matmul_k<<<blocks,tpb,size>>>(\n",
    "        m.data_ptr<float>(), n.data_ptr<float>(), output.data_ptr<float>(), h, w, k, TW, size);\n",
    "    C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
    "    return output;\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3c81f01-589e-41f9-899a-a2050b1b4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'matmul'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27f0a108-848e-4bbd-b79b-2f19bf1b7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig(fname, src):\n",
    "    res = re.findall(rf'^(.+\\s+{fname}\\(.*?\\))\\s*{{?\\s*$', src, re.MULTILINE)\n",
    "    return res[0]+';' if res else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb1a24b0-0cb9-46dd-97fa-4df0bca629d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch::Tensor matmul(torch::Tensor m, torch::Tensor n);'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpp_src = get_sig(fname, cuda_src)\n",
    "cpp_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7352ea50-96ca-470e-9a16-360bf09ddd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/ubuntu/.cache/torch_extensions/py311_cu121 as PyTorch extensions root...\n",
      "The input conditions for extension module inline_ext have changed. Bumping to version 3 and re-building as inline_ext_v3...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/ubuntu/.cache/torch_extensions/py311_cu121/inline_ext/build.ninja...\n",
      "Building extension module inline_ext_v3...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] c++ -MMD -MF main.o.d -DTORCH_EXTENSION_NAME=inline_ext_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/TH -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/miniconda3/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/ubuntu/.cache/torch_extensions/py311_cu121/inline_ext/main.cpp -o main.o \n",
      "[2/3] /usr/local/cuda/bin/nvcc --generate-dependencies-with-compile --dependency-output cuda.cuda.o.d -DTORCH_EXTENSION_NAME=inline_ext_v3 -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/torch/csrc/api/include -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/TH -isystem /home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /home/ubuntu/miniconda3/include/python3.11 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -std=c++17 -c /home/ubuntu/.cache/torch_extensions/py311_cu121/inline_ext/cuda.cu -o cuda.cuda.o \n",
      "[3/3] c++ main.o cuda.cuda.o -shared -L/home/ubuntu/miniconda3/lib/python3.11/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o inline_ext_v3.so\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module inline_ext_v3...\n"
     ]
    }
   ],
   "source": [
    "module = load_cuda(cuda_src, cpp_src, [fname], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68abdcff-269a-49f0-91c4-5db42fb45b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1c,m2c = m1.contiguous().cuda(),m2.contiguous().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b2b8a7d-a337-4470-a3b4-6fa96bc8caad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated shared memory size: 8192 bytes\n",
      "Maximum shared memory per block: 8192 bytes\n",
      "TW: 32 blocks.x: 1 blocks.y: 1563\n",
      "tpb.x: 32 tpb.y: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.matmul(m1c,m2c).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1895e28c-8fda-403c-bd43-95a481960fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated shared memory size: 8192 bytes\n",
      "Maximum shared memory per block: 8192 bytes\n",
      "TW: 32 blocks.x: 1 blocks.y: 1563\n",
      "tpb.x: 32 tpb.y: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(module.matmul(m1c,m2c), m1c@m2c).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed8ee53-959c-4935-b75e-6d21dee76881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cfa46c-927d-4a3b-ad05-88fe9ca610c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
